# -*- coding: utf-8 -*-
"""Data_Acquisition_Case_Study.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GcC6a-VTDvOJEP5ZMqWUp7gcxMxGriSp

#Data Acquisition Case Study

## Q1. Write Python code to create a new file named "sample_data.txt" in your documents folder and write the following content to it

ICTAK

Thejaswini,

Technopark Rd,

Technopark Campus,

Thiruvananthapuram,

Kerala 695581
"""

file_path = "sample_data.txt"


content = """ICTAK

Thejaswini,

Technopark Rd,

Technopark Campus,

Thiruvananthapuram,

Kerala 695581"""

with open(file_path, "w") as file:
    file.write(content)

print(f"File created at: {file_path}")

"""## Q2. Write Python code to read and print the contents in "sample_data.txt"
"""

with open("sample_data.txt", "r") as file:
    content = file.read()

print("Contents of sample_data.txt:\n")
print(content)

"""## Q3. Write Python code to check if "sample_data.txt" exists in documents folder"""

if os.path.exists("sample_data.txt"):
    print("sample_data.txt exists in the current directory.")
else:
    print("sample_data.txt does NOT exist in the current directory.")

"""## Q4: Save the following dataframe content to a CSV file (data.csv) in your downloads folder"""

import pandas as pd

data = {"Id": [1, 2, 3],
        "Name": ["Alice", "Bob", "Charlie"],
        "Subject": ["Science", "Maths", "History"]}
df = pd.DataFrame(data)

import pandas as pd
import os


data = {
    "Id": [1, 2, 3],
    "Name": ["Alice", "Bob", "Charlie"],
    "Subject": ["Science", "Maths", "History"]
}

df = pd.DataFrame(data)

downloads_folder = os.path.join(os.path.expanduser("~"), "Downloads")
os.makedirs(downloads_folder, exist_ok=True)


file_path = os.path.join(downloads_folder, "data.csv")


df.to_csv(file_path, index=False)

print(f"data.csv successfully saved to: {file_path}")

"""## Q5: Save the above dataframe content to an Excel (data.xlsx, sheet name: Sheet1) file in your documents folder"""

import pandas as pd
import os


data = {
    "Id": [1, 2, 3],
    "Name": ["Alice", "Bob", "Charlie"],
    "Subject": ["Science", "Maths", "History"]
}
df = pd.DataFrame(data)

r
documents_folder = os.path.join(os.path.expanduser("~"), "Documents")
os.makedirs(documents_folder, exist_ok=True)


file_path = os.path.join(documents_folder, "data.xlsx")


df.to_excel(file_path, index=False, sheet_name="Sheet1")

print(f"Excel file successfully saved to: {file_path}")

"""## Q6. Write code to get the list of files in your Downloads folder and save it to a CSV file name "download_list.csv"
"""

import os
import pandas as pd


downloads_folder = os.path.join(os.path.expanduser("~"), "Downloads")


file_list = [f for f in os.listdir(downloads_folder) if os.path.isfile(os.path.join(downloads_folder, f))]

df = pd.DataFrame(file_list, columns=["File Name"])


csv_path = os.path.join(downloads_folder, "download_list.csv")
df.to_csv(csv_path, index=False)

print(f"List of files saved to: {csv_path}")

"""## Q7. Write Python code to save the contents of the given random_array variable as a numpy file"""

import numpy as np
random_array = np.random.rand(10, 10)

import numpy as np


random_array = np.random.rand(10, 10)


np.save("random_array.npy", random_array)

print("random_array.npy file has been saved successfully.")

"""## Q8. Write python code to save the contents of the above numpy file as text file named "random.txt" with a delimitter of ";" to Documents folder"""

import numpy as np
import os

random_array = np.load("random_array.npy")

documents_folder = os.path.join(os.path.expanduser("~"), "Documents")
os.makedirs(documents_folder, exist_ok=True)


text_file_path = os.path.join(documents_folder, "random.txt")

np.savetxt(text_file_path, random_array, delimiter=";", fmt="%.4f")

print(f"Array successfully saved to: {text_file_path}")

"""## Download and analyze Bike Sharing Dataset (hour.csv) for UCI Irvin Repository (https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset) and answer the following questions"""

import urllib.request
import zipfile

url = "http://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip"
filename = "Bike-Sharing-Dataset.zip"

urllib.request.urlretrieve(url, filename)


with zipfile.ZipFile(filename, 'r') as zip_ref:
    zip_ref.extractall()

print("Dataset downloaded and extracted.")

import os

os.listdir()

"""## Q9. What is the size of the dataset? (Number of rows and columns)


"""

import pandas as pd


df = pd.read_csv("hour.csv")


rows, columns = df.shape
print(f"Number of rows: {rows}")
print(f"Number of columns: {columns}")

df.head()

"""## Q10. What are the data types of each column?

"""

df.dtypes

"""## Q11. Are there any missing values in the dataset? If so, which columns have missing values and how many?"""

missing_values = df.isnull().sum()

missing_values = missing_values[missing_values > 0]


if missing_values.empty:
    print(" There are no missing values in the dataset.")
else:
    print(" Missing values found:\n")
    print(missing_values)

"""## Q.12. For the windspeed column, calculate the mean, median, and standard deviation."""

# Mean
mean_wind = df['windspeed'].mean()

# Median
median_wind = df['windspeed'].median()

# Standard Deviation
std_wind = df['windspeed'].std()

# Display results
print(f"Mean windspeed       : {mean_wind:.4f}")
print(f"Median windspeed     : {median_wind:.4f}")
print(f"Standard deviation   : {std_wind:.4f}")

"""## Q13. Identify any potential outliers in a numerical column of your choice. Explain your approach.

"""

# Step 1: Select the column
col = 'windspeed'

# Step 2-4: Calculate Q1, Q3, IQR, and bounds
Q1 = df[col].quantile(0.25)
Q3 = df[col].quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Step 5: Identify outliers
outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]

print(f"Total outliers in '{col}': {len(outliers)}")
print(f"Lower bound: {lower_bound:.4f}, Upper bound: {upper_bound:.4f}")

"""## Q.14 Find the correlation between numerical columns and discuss any interesting relationships."""

correlation_matrix = df.corr(numeric_only=True)

correlation_matrix

"""## Q.15 Based on your analysis, provide a brief summary of any insights or patterns you discovered in the dataset.

1. Dataset Overview
Total records: 17,379

Columns: 17

No missing values were found in the dataset — ✅ data is clean.

 2. Weather & Environment Effects
Temperature (temp/atemp) has a moderate positive correlation with total bike usage (cnt). Warmer weather → more rentals.

Humidity (hum) and windspeed both show a slight negative correlation — likely because high humidity and wind make biking less comfortable.

 3. User Type Influence
Registered users (registered) have a very strong positive correlation (~0.97) with total usage — they are the main contributors to rental count.

Casual users correlate moderately (~0.53) — meaning weekend or occasional users contribute, but far less than subscribers.

 4. Hourly and Temporal Trends (from earlier rows)
Rentals are lower at night (e.g., hour = 0–5), start increasing in the morning, and peak around commuting hours (8–9 AM and 5–6 PM).

You can further visualize this with a line plot grouped by hour to confirm patterns.

 5. Outliers
Detected outliers in columns like windspeed using the IQR method — they should be investigated or cleaned for modeling tasks.

 Final Thoughts:
Time (hour/month/weekday) and user type are critical dimensions for understanding and forecasting bike usage.

Weather features affect behavior but to a lesser extent.

This dataset is well-suited for building predictive models for bike demand using regression or time-series methods.

## Q.16 In which season (Spring, Summer, Fall, Winter) people rented bikes the most?
"""

# Map numeric season to names
season_map = {1: 'Spring', 2: 'Summer', 3: 'Fall', 4: 'Winter'}
df['season_name'] = df['season'].map(season_map)

# Group by season and sum the total bike rentals
season_rentals = df.groupby('season_name')['cnt'].sum().sort_values(ascending=False)

# Display results
print("Total bike rentals by season:\n")
print(season_rentals)

"""## Q.17 What is the peak hour in which bike rents the most?"""

# Group by hour and sum total bike rentals
hourly_rentals = df.groupby('hr')['cnt'].sum()

# Find the hour with the maximum rentals
peak_hour = hourly_rentals.idxmax()
peak_rentals = hourly_rentals.max()

print(f"Peak hour: {peak_hour}:00 with {peak_rentals} rentals")

"""## Q.18 In which day of a week bikes rents out most?"""

# Map weekday numbers to names
weekday_map = {0: 'Sunday', 1: 'Monday', 2: 'Tuesday', 3: 'Wednesday',
               4: 'Thursday', 5: 'Friday', 6: 'Saturday'}

df['weekday_name'] = df['weekday'].map(weekday_map)

# Sum bike rentals by weekday
weekday_rentals = df.groupby('weekday_name')['cnt'].sum()

# Sort by rental counts descending to find the day with most rentals
weekday_rentals = weekday_rentals.sort_values(ascending=False)

print("Total bike rentals by day of the week:\n")
print(weekday_rentals)
print(f"\nDay with most bike rentals: {weekday_rentals.idxmax()}")

"""## Q.19 In which hour Casual users rents bikes the most?"""

# Group by hour and sum casual user rentals
casual_hourly = df.groupby('hr')['casual'].sum()

# Find the hour with maximum casual rentals
peak_casual_hour = casual_hourly.idxmax()
peak_casual_rentals = casual_hourly.max()

print(f"Peak hour for casual users: {peak_casual_hour}:00 with {peak_casual_rentals} rentals")

"""## Q.20 What is the maximum temperature observed in each of the seasons?"""

# Using the 'season_name' column we created earlier

# Find max temperature for each season
max_temp_by_season = df.groupby('season_name')['temp'].max()

print("Maximum normalized temperature observed in each season:")
print(max_temp_by_season)